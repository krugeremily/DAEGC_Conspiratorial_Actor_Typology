{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilykruger/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/emilykruger/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # for scripts\n",
    "project_root = '/Users/emilykruger/Documents/GitHub/CSH-Internship'\n",
    "functions_dir = os.path.join(project_root, 'src/functions')\n",
    "daegc_dir = os.path.join(project_root, 'src/DAEGC')\n",
    "\n",
    "sys.path.append(project_root) #for local notebook\n",
    "sys.path.append(functions_dir) #for local notebook\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import regex as re\n",
    "from src.functions.linguistic_features import remove_emojis, remove_tags, count_emojis, preprocess_text, count_pos_tags\n",
    "from textstat import flesch_reading_ease\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import multiprocessing as mp\n",
    "\n",
    "# to get cluster labels\n",
    "import torch\n",
    "from src.DAEGC.DAEGC import DAEGC\n",
    "from src.functions.daegc_helpers import *\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Code for Linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, code will be written to extract linguistic features from the dataset. It will be done on a small subsample. Afterwards code will be transferred to a script to run on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv('../data/selected_groups_with_transcriptions.csv.gzip', compression='gzip')\n",
    "channels = pd.read_csv('../data/channel_subsample.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = groups.drop(columns=['Unnamed: 0'], axis=1)\n",
    "groups['group_or_channel'] = 'group'\n",
    "groups.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = channels.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "channels['group_or_channel'] = 'channel'\n",
    "channels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take random sample of 100k rows of both df where either message or fwd_message contains data and combine\n",
    "sample_groups = groups[groups['message'].notnull() | groups['fwd_message'].notnull()].sample(n=1000, random_state=42)\n",
    "sample_channels = channels = channels[channels['message'].notnull() | channels['fwd_message'].notnull()].sample(n=1000, random_state=42)\n",
    "combined = pd.concat([sample_groups, sample_channels], ignore_index=True, axis=0)\n",
    "combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only UID and message\n",
    "messages = combined[['UID_key', 'message', 'fwd_message', 'group_or_channel']]\n",
    "\n",
    "#remove emojis\n",
    "cleaned_messages = []\n",
    "for message in messages['message'].astype(str):\n",
    "    cleaned_messages.append(remove_emojis(message))\n",
    "\n",
    "cleaned_fwd_messages = []\n",
    "for message in messages['fwd_message'].astype(str):\n",
    "    cleaned_fwd_messages.append(remove_emojis(message))\n",
    "\n",
    "messages['message_string'] = cleaned_messages\n",
    "messages['fwd_message_string'] = cleaned_fwd_messages\n",
    "messages['message_string'] = messages['message_string'].astype(str)\n",
    "messages['fwd_message_string'] = messages['fwd_message_string'].astype(str)\n",
    "\n",
    "#if message, take message else take fwd_message\n",
    "messages['final_message'] = messages['message'].where(messages['message'].notnull(), messages['fwd_message'])\n",
    "messages['final_message_string'] = messages['message_string'].where(messages['message_string'] != 'nan', messages['fwd_message_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['preprocessed_message'] = messages['final_message_string'].apply(preprocess_text)\n",
    "\n",
    "#delete uneccessary columns\n",
    "messages = messages.drop(columns=['message', 'fwd_message', 'message_string', 'fwd_message_string'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.to_csv('../data/messages_sample.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Re-Running Below Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for re-running\n",
    "messages = pd.read_csv('../data/samples/messages_sample_2000.csv.gzip', compression='gzip').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-Based Features & POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num sentences\n",
    "messages['sent_count'] = messages['final_message_string'].apply(lambda x: len(re.split(r'[.!?]+', x)) if x else 0)\n",
    "#num words\n",
    "messages['word_count'] = messages['final_message_string'].apply(lambda x: len(re.findall(r'\\w+', x)) if x else 0)\n",
    "#avg sentence length (words per sentence)\n",
    "messages['avg_sent_length'] = messages.apply(lambda row: row['word_count'] / row['sent_count'] if row['sent_count'] > 0 else 0, axis=1)\n",
    "#avg word length (characters per word)\n",
    "messages['avg_word_length'] = messages.apply(lambda row: len(row['final_message_string'].replace(' ', '')) / row['word_count'] if row['word_count'] > 0 else 0, axis=1)\n",
    "#num exclamations (multiple ! coutn as one exclamation)\n",
    "messages['exclamation_count'] = messages['final_message_string'].apply(lambda x: len(re.findall(r'!+', x)) if x else 0)\n",
    "#num questions (multiple ? count as one question)\n",
    "messages['question_count'] = messages['final_message_string'].apply(lambda x: len(re.findall(r'\\?+', x)) if x else 0)\n",
    "#num emojis \n",
    "messages['emoji_count'] = messages['final_message'].apply(lambda x: count_emojis(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use count_pos_tags func to count nouns, verbs and adj\n",
    "messages['noun_count'] = messages['final_message_string'].apply(lambda x: count_pos_tags(x)[0])\n",
    "messages['verb_count'] = messages['final_message_string'].apply(lambda x: count_pos_tags(x)[1])\n",
    "messages['adj_count'] = messages['final_message_string'].apply(lambda x: count_pos_tags(x)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use TextStat to compute Flesch Reading Ease score on final_message_string\n",
    "messages['flesch_reading_ease'] = messages['final_message_string'].apply(flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head(5)\n",
    "messages.to_csv('../data/messages_with_features.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Complexity Classifier Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline, DistilBertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('MiriUll/distilbert-german-text-complexity')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('MiriUll/distilbert-german-text-complexity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Mit solchen Drohungen kommt sie nie mehr zurück \", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"MiriUll/distilbert-german-text-complexity\")\n",
    "print(pipe('Das ist ein einfacher Satz.'))\n",
    "print(pipe('Obwohl der junge Wissenschaftler sich intensiv auf seine Forschungsarbeit konzentrierte, war er oft von den unvorhersehbaren und lauten Bauarbeiten im Nachbargebäude abgelenkt, die seine produktivsten Stunden regelmäßig störten.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Emoji Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = pd.read_csv('../data/archive/Emoji_Sentiment_Data_v1.0.csv')\n",
    "#emoji sentiment column based on max value of positive neutral or negative\n",
    "emojis['sentiment'] = emojis[['Positive', 'Neutral', 'Negative']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-formatting Liwc Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/LIWC2007_German.dic'\n",
    "skiprows = 70  # Specify the number of rows to skip\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r', encoding='latin1') as file:\n",
    "    # Step 1: Skip the specified number of rows\n",
    "    for _ in range(skiprows):\n",
    "        next(file)\n",
    "    \n",
    "    # Read the file line-by-line\n",
    "    for line in file:\n",
    "        split_line = line.strip().split('\\t')\n",
    "        word = split_line[0]\n",
    "        categories = split_line[1:]\n",
    "        data.append([word, categories])\n",
    "\n",
    "# Step 2: Create DataFrame with flexible columns\n",
    "# Define headers\n",
    "headers = ['word', 'categories']\n",
    "\n",
    "# Step 3: Create DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Print the DataFrame to check the result\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('categories')\n",
    "df['categories'] = df['categories'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_categories = {\n",
    "    1: 'Pronoun',\n",
    "    2: 'I',\n",
    "    3: 'We',\n",
    "    4: 'Self',\n",
    "    5: 'You',\n",
    "    6: 'Other',\n",
    "    7: 'Negate',\n",
    "    8: 'Assent',\n",
    "    9: 'Article',\n",
    "    10: 'Preps',\n",
    "    11: 'Number',\n",
    "    12: 'Affect',\n",
    "    13: 'Posemo',\n",
    "    14: 'Posfeel',\n",
    "    15: 'Optim',\n",
    "    16: 'Negemo',\n",
    "    17: 'Anx',\n",
    "    18: 'Anger',\n",
    "    19: 'Sad',\n",
    "    20: 'Cogmech',\n",
    "    21: 'Cause',\n",
    "    22: 'Insight',\n",
    "    23: 'Discrep',\n",
    "    24: 'Inhib',\n",
    "    25: 'Tentat',\n",
    "    26: 'Certain',\n",
    "    27: 'Senses',\n",
    "    28: 'See',\n",
    "    29: 'Hear',\n",
    "    30: 'Feel',\n",
    "    31: 'Social',\n",
    "    32: 'Comm',\n",
    "    33: 'Othref',\n",
    "    34: 'Friends',\n",
    "    35: 'Family',\n",
    "    36: 'Humans',\n",
    "    37: 'Time',\n",
    "    38: 'Past',\n",
    "    39: 'Present',\n",
    "    40: 'Future',\n",
    "    41: 'Space',\n",
    "    42: 'Up',\n",
    "    43: 'Down',\n",
    "    44: 'Incl',\n",
    "    45: 'Excl',\n",
    "    46: 'Motion',\n",
    "    47: 'Occup',\n",
    "    48: 'School',\n",
    "    49: 'Job',\n",
    "    50: 'Achieve',\n",
    "    51: 'Leisure',\n",
    "    52: 'Home',\n",
    "    53: 'Sports',\n",
    "    54: 'TV',\n",
    "    55: 'Music',\n",
    "    56: 'Money',\n",
    "    57: 'Metaph',\n",
    "    58: 'Relig',\n",
    "    59: 'Death',\n",
    "    60: 'Physcal',\n",
    "    61: 'Body',\n",
    "    62: 'Sexual',\n",
    "    63: 'Eating',\n",
    "    64: 'Sleep',\n",
    "    65: 'Groom',\n",
    "    66: 'Swear',\n",
    "    67: 'Nonfl',\n",
    "    68: 'Fillers'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat_name'] = df['categories'].map(liwc_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the order of the columns so that its word, cat_name, categories\n",
    "df = df[['word', 'cat_name', 'categories']]\n",
    "\n",
    "#write df to txt file but omit index and column header\n",
    "df.to_csv('../data/liwc_german_2007.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making txt file for GAWK script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'messages_sample_10'\n",
    "sample = pd.read_csv(f'../data/samples/{filename}.csv.gzip', compression='gzip').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep UID_key and final_message_string and save as txt without \"\" around messages\n",
    "\n",
    "sample = sample[['UID_key', 'final_message_string']]\n",
    "sample.to_csv(f'../data/samples/{filename}.txt', sep='\\t', index=False, header=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10 #how big of a sample to take from each dataset\n",
    "random_state = 42\n",
    "\n",
    "########## LOAD AND PREPARE DATASET ##########\n",
    "\n",
    "#load two datasets, drop unnecessary columns and add column to indicate group or channel\n",
    "groups = pd.read_csv('../data/selected_groups_with_transcriptions.csv.gzip', compression='gzip').drop(columns=['Unnamed: 0'], axis=1)\n",
    "channels = pd.read_csv('../data/channel_subsample.csv.gzip', compression='gzip').drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "\n",
    "\n",
    "groups['group_or_channel'] = 'group'\n",
    "channels['group_or_channel'] = 'channel'\n",
    "\n",
    "\n",
    "#take random sample of both df where either message or fwd_message (or transcribedmessage if group) contains data and combine\n",
    "sample_groups = groups[groups['message'].notnull() | groups['fwd_message'].notnull() | groups['transcribed_message'].notnull()].sample(n=sample_size, random_state=random_state)\n",
    "sample_channels = channels = channels[channels['message'].notnull() | channels['fwd_message'].notnull()].sample(n=sample_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([sample_groups, sample_channels], ignore_index=True, axis=0)\n",
    "\n",
    "#keep only necessary columns\n",
    "messages = combined[['UID_key', 'message', 'fwd_message', 'transcribed_message', 'group_or_channel']]\n",
    "\n",
    "#remove emojis and links\n",
    "cleaned_messages = []\n",
    "for message in messages['message'].astype(str):\n",
    "    message = remove_tags(message)\n",
    "    cleaned_messages.append(remove_emojis(message))\n",
    "\n",
    "cleaned_fwd_messages = []\n",
    "for message in messages['fwd_message'].astype(str):\n",
    "    message = remove_tags(message)\n",
    "    cleaned_fwd_messages.append(remove_emojis(message))\n",
    "\n",
    "messages['message_string'] = cleaned_messages\n",
    "messages['fwd_message_string'] = cleaned_fwd_messages\n",
    "messages['message_string'] = messages['message_string'].astype(str)\n",
    "messages['fwd_message_string'] = messages['fwd_message_string'].astype(str)\n",
    "\n",
    "#if message, take message else take fwd_message else take transcribed message\n",
    "messages['final_message'] = np.where(messages['message'].notnull(), messages['message'],\n",
    "                                    np.where(messages['fwd_message'].notnull(), messages['fwd_message'],\n",
    "                                             messages['transcribed_message'])).astype(str)\n",
    "messages['final_message_string'] = np.where(messages['message_string'] != 'nan', messages['message_string'],\n",
    "                                    np.where(messages['fwd_message_string'] != 'nan', messages['fwd_message_string'],\n",
    "                                             messages['transcribed_message'])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['final_message_string'] = messages['final_message_string'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gawk -f ../src/analysis/liwc_category_ratios.awk ../data/liwc_german_2007.txt ../data/samples/messages_sample_200.txt > ../results/liwc_ratios.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the output file but remove last column\n",
    "liwc_ratios = pd.read_csv('../results/liwc_ratios.csv', sep=',')\n",
    "liwc_ratios = liwc_ratios.iloc[:, :-1]\n",
    "liwc_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features = pd.read_csv('../results/messages_with_features_200.csv.gzip', compression='gzip').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat liwc_ratios and ling_features based on UID_key\n",
    "merged = pd.merge(ling_features, liwc_ratios, on='UID_key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(model=\"aari1995/German_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"Ich liebe die Bahn. Pünktlich wie immer ... -.-\",\"Krasser Service\"]\n",
    "result = sentiment_model(sentence)\n",
    "print(result)\n",
    "#Output:\n",
    "#[{'label': 'negative', 'score': 0.4935680031776428},{'label': 'positive', 'score': 0.5790663957595825}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Assuming 'sentiment_model' is already loaded\n",
    "# Load the tokenizer corresponding to your sentiment model\n",
    "tokenizer = AutoTokenizer.from_pretrained('aari1995/German_Sentiment')  # Replace 'model_name' with the actual model name\n",
    "\n",
    "sentiment_aari = []\n",
    "\n",
    "for message in messages['final_message_string']:\n",
    "    # Encode the message, truncate to max length of the model, and only keep the input_ids\n",
    "    inputs = tokenizer.encode(message, return_tensors='pt', max_length=512, truncation=True)\n",
    "    # Decode back to text string, to feed into the sentiment model as expected\n",
    "    truncated_message = tokenizer.decode(inputs[0], skip_special_tokens=True)\n",
    "    result = sentiment_model(truncated_message)\n",
    "    sentiment_aari.append(result[0]['label'])\n",
    "\n",
    "messages['sentiment_aari'] = sentiment_aari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = []\n",
    "neg_sent = []\n",
    "neutral_sent = []\n",
    "\n",
    "for message in tqdm(messages['final_message_string'], desc = 'Extracting Sentiment'):\n",
    "    # if message is empty, don't calculate sentiment\n",
    "    if message == '' or message == 'nan':\n",
    "        pos_sent.append(np.nan)\n",
    "        neg_sent.append(np.nan)\n",
    "        neutral_sent.append(np.nan)\n",
    "    else:\n",
    "        # encode & decode message and truncate to max length that model can handle\n",
    "        result = sentiment_model(message[:512])\n",
    "        sent = (result[0]['label'])\n",
    "        if sent == 'positive':\n",
    "            pos_sent.append(1)\n",
    "            neg_sent.append(0)\n",
    "            neutral_sent.append(0)\n",
    "        elif sent == 'negative':\n",
    "            pos_sent.append(0)\n",
    "            neg_sent.append(1)\n",
    "            neutral_sent.append(0)\n",
    "        elif sent == 'neutral':\n",
    "            pos_sent.append(0)\n",
    "            neg_sent.append(0)\n",
    "            neutral_sent.append(1)\n",
    "        else:\n",
    "            pos_sent.append(np.nan)\n",
    "            neg_sent.append(np.nan)\n",
    "            neutral_sent.append(np.nan)\n",
    "\n",
    "messages['positive_sentiment'] = pos_sent\n",
    "messages['negative_sentiment'] = neg_sent\n",
    "messages['neutral_sentiment'] = neutral_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Initialize sentiment lists\n",
    "pos_sent = [np.nan] * len(messages['final_message_string'])\n",
    "neg_sent = [np.nan] * len(messages['final_message_string'])\n",
    "neutral_sent = [np.nan] * len(messages['final_message_string'])\n",
    "\n",
    "# Map sentiment labels to list indices\n",
    "sentiment_map = {\n",
    "    'positive': (1, 0, 0),\n",
    "    'negative': (0, 1, 0),\n",
    "    'neutral': (0, 0, 1)\n",
    "}\n",
    "\n",
    "# Process messages\n",
    "for idx, message in tqdm(enumerate(messages['final_message_string']), desc='Extracting Sentiment', total=len(messages['final_message_string'])):\n",
    "    # Skip empty messages\n",
    "    if message in ('', 'nan'):\n",
    "        continue\n",
    "\n",
    "    # Run sentiment analysis\n",
    "    result = sentiment_model(message[:512])  # Use the pipeline directly with the message text\n",
    "    sent = result[0]['label']\n",
    "\n",
    "    # Update sentiment lists\n",
    "    if sent in sentiment_map:\n",
    "        pos_sent[idx], neg_sent[idx], neutral_sent[idx] = sentiment_map[sent]\n",
    "\n",
    "# Assign results back to DataFrame\n",
    "messages['positive_sentiment'] = pos_sent\n",
    "messages['negative_sentiment'] = neg_sent\n",
    "messages['neutral_sentiment'] = neutral_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in tqdm(messages['final_message_string']):\n",
    "    sentiment = sentiment_model(message[:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "text = \"Erneuter Streik in der S-Bahn\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained('ssary/XLM-RoBERTa-German-sentiment')\n",
    "tokenizer = AutoTokenizer.from_pretrained('ssary/XLM-RoBERTa-German-sentiment')\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "sentiment_classes = ['negative', 'neutral', 'positive']\n",
    "print(sentiment_classes[predictions.argmax()]) # for the class with highest probability\n",
    "print(predictions) # for each class probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('../data/samples/messages_sample_200.csv.gzip', compression='gzip').drop('Unnamed: 0', axis=1)\n",
    "messages['final_message_string'] = messages['final_message_string'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict sentiment on all messages\n",
    "sentiment = []\n",
    "neg_prob = []\n",
    "neu_prob = []\n",
    "pos_prob = []\n",
    "\n",
    "for message in messages['final_message_string']:\n",
    "    inputs = tokenizer(message, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment_classes = ['negative', 'neutral', 'positive']\n",
    "    sentiment.append(sentiment_classes[predictions.argmax()])\n",
    "    neg_prob.append(predictions[0][0].item())\n",
    "    neu_prob.append(predictions[0][1].item())\n",
    "    pos_prob.append(predictions[0][2].item())\n",
    "\n",
    "messages['sentiment'] = sentiment\n",
    "messages['neg_prob'] = neg_prob\n",
    "messages['neu_prob'] = neu_prob\n",
    "messages['pos_prob'] = pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all messages with their sentiment\n",
    "for i, row in messages.iterrows():\n",
    "    print(f'{row[\"final_message_string\"]} - {row[\"sentiment\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[['final_message_string', 'sentiment', 'sentiment_aari']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all messages with their sentiment\n",
    "for i, row in messages.iterrows():\n",
    "    print(f'{row[\"final_message_string\"]}\\nRoberta: {row[\"sentiment\"]}\\nAari: {row[\"sentiment_aari\"]}\\n', '-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/samples/messages_sample_200.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = pd.read_csv('../data/channel_subsample.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from googleapiclient import discovery\n",
    "import json\n",
    "from config import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = discovery.build(\n",
    "\"commentanalyzer\",\n",
    "\"v1alpha1\",\n",
    "developerKey=API_KEY,\n",
    "discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "static_discovery=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/post-aggregation/author_200.csv.gzip', compression = 'gzip')\n",
    "df['final_message_string'] = df['final_message_string'].astype(str)\n",
    "df['toxicity'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_detection(sentences, client):\n",
    "    toxic = []\n",
    "    for sent in sentences:\n",
    "        analyze_request = {\n",
    "            'comment': { 'text': f\"{sent}\" },\n",
    "            'languages' : [\"de\"],\n",
    "            'requestedAttributes': {'TOXICITY': {}},\n",
    "        }\n",
    "\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "        j = json.dumps(response, indent=2)\n",
    "        #print(json.loads(j)['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "        toxic.append(json.loads(j)['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "    avg = sum(toxic)/len(toxic)\n",
    "    print(avg)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def toxicity_detection(sentences):\n",
    "#     toxic = []\n",
    "#     for sent in sentences:\n",
    "#         analyze_request = {\n",
    "#             'comment': { 'text': f\"{sent}\" },\n",
    "#             'languages' : [\"de\"],\n",
    "#             'requestedAttributes': {'TOXICITY': {}},\n",
    "#         }\n",
    "\n",
    "#         response = client.comments().analyze(body=analyze_request).execute()\n",
    "#         j = json.dumps(response, indent=2)\n",
    "#         #print(json.loads(j)['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "#         toxic.append(json.loads(j)['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "#     return sum(toxic)/len(toxic)\n",
    "\n",
    "\n",
    "# # n= 10000\n",
    "# # list_df = [sample[i:i+n] for i in range(0,len(sample),n)]\n",
    "\n",
    "\n",
    "# #final_toxic_list = []\n",
    "# # for df in list_df:\n",
    "# for i in tqdm(range(len(sample_df))):\n",
    "#     row = sample_df.iloc[i]\n",
    "#     #toxic = []\n",
    "#     if row['toxicity'] == 0: \n",
    "\n",
    "#         tmp = [sent.strip() for sent in re.split(r'[.!?]', row.final_message_string) if len(sent.split()) > 5]\n",
    "\n",
    "#         if (len(tmp) > 100):\n",
    "#             tmp = random.sample(tmp, 100)\n",
    "#         if (len(tmp) > 1):\n",
    "#             row['toxicity'] = toxicity_detection(tmp)\n",
    "\n",
    "#     sample_df.at[i, 'toxicity'] = row['toxicity']\n",
    "\n",
    "#     #df.at[i, 'toxicity'] = toxic\n",
    "#     #final_toxic_list.append(df)\n",
    "\n",
    "# # con = pd.concat(final_toxic_list)\n",
    "# # con.to_csv('fa_toxic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split df into chunks\n",
    "n= 20\n",
    "list_df = [df[i:i+n] for i in range(0,len(df),n)]\n",
    "\n",
    "#iterate over chunks and rows to extract toxicity score\n",
    "final_toxic_list = []\n",
    "for df in list_df:\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        if row['toxicity'] == 0: \n",
    "            #split message into list of sentences to pass to toxicity detection function\n",
    "            tmp = [sent.strip() for sent in re.split(r'[.!?]', row['final_message_string']) if len(sent.split()) > 5]\n",
    "\n",
    "            if (len(tmp) > 100):\n",
    "                tmp = random.sample(tmp, 100)\n",
    "            #print(tmp)\n",
    "            if (len(tmp) > 1):\n",
    "                row['toxicity'] = toxicity_detection(tmp, client)\n",
    "            else:\n",
    "                print('no sentence')\n",
    "        df.at[df.index[i], 'toxicity'] = row['toxicity']\n",
    "        print('df.at...', df.at[df.index[i], 'toxicity'])\n",
    "    final_toxic_list.append(df)\n",
    "\n",
    "#concat chunks\n",
    "df_after = pd.concat(final_toxic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['final_message_string'] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_toxic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_after[df_after['toxicity'] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../results/post-aggregation/author_200.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['toxicity'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forwarded Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df[sample_df['forwarded_message'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = pd.read_csv('../data/samples/messages_sample_200.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample[new_sample['forwarded_message'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample['final_message_string'] = new_sample['final_message_string'].astype(str)\n",
    "new_sample['final_message'] = new_sample['final_message'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample['sent_count'] = new_sample['final_message_string'].apply(lambda x: len(re.split(r'[.!?]+', x)) if x != '' and x != 'nan' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample['question_count'] = new_sample['final_message_string'].apply(lambda x: len(re.findall(r'\\?+', x)) if x else 0)\n",
    "#num emojis \n",
    "new_sample['emoji_count'] = new_sample['final_message'].apply(lambda x: count_emojis(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "\n",
    "\n",
    "for message in tqdm(new_sample['final_message_string'], desc = 'Extracting POS Tag counts'):\n",
    "        noun, verb, adj = count_pos_tags(message)\n",
    "        nouns.append(noun)\n",
    "        verbs.append(verb)\n",
    "        adjectives.append(adj)\n",
    "                        \n",
    "new_sample['noun_count'] = nouns\n",
    "new_sample['verb_count'] = verbs\n",
    "new_sample['adj_count'] = adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200\n",
    "pre_agg = pd.read_csv(f'../results/pre-aggregation/liwcANDfeatures_results_{sample_size}.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_agg = pd.get_dummies(pre_agg, columns=['group_or_channel', 'flesch_reading_ease_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation dictionary\n",
    "agg_dict = {\n",
    "    # COUNT\n",
    "    'UID_key': 'count',\n",
    "\n",
    "    # SUM\n",
    "    'own_message': 'sum',\n",
    "    'forwarded_message': 'sum',\n",
    "    'noun_count': 'sum',\n",
    "    'verb_count': 'sum',\n",
    "    'adj_count': 'sum',\n",
    "    'positive_sentiment': 'sum',\n",
    "    'negative_sentiment': 'sum',\n",
    "    'neutral_sentiment': 'sum',\n",
    "    'group_or_channel_channel': 'sum',\n",
    "    'group_or_channel_group': 'sum',\n",
    "    'flesch_reading_ease_class_difficult': 'sum',\n",
    "    'flesch_reading_ease_class_easy': 'sum',\n",
    "    'flesch_reading_ease_class_fairly difficult': 'sum',\n",
    "    'flesch_reading_ease_class_fairly easy': 'sum',\n",
    "    'flesch_reading_ease_class_standard': 'sum',\n",
    "    'flesch_reading_ease_class_unclassified': 'sum',\n",
    "    'flesch_reading_ease_class_very confusing': 'sum',\n",
    "    'flesch_reading_ease_class_very easy': 'sum',\n",
    "\n",
    "    # AVG\n",
    "    'sent_count': 'mean',\n",
    "    'word_count': 'mean',\n",
    "    'avg_sent_length': 'mean',\n",
    "    'avg_word_length': 'mean',\n",
    "    'exclamation_count': 'mean',\n",
    "    'question_count': 'mean',\n",
    "    'emoji_count': 'mean',\n",
    "    'flesch_reading_ease': 'mean',\n",
    "    'liwc_I': 'mean',\n",
    "    'liwc_We': 'mean',\n",
    "    'liwc_You': 'mean',\n",
    "    'liwc_Other': 'mean',\n",
    "    'liwc_Affect': 'mean',\n",
    "    \n",
    "    # ' '.JOIN\n",
    "    'fwd_message': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    'fwd_message_string': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    'final_message': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    'final_message_string': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict for aggregatopn\n",
    "agg = pre_agg.groupby(['author', 'date']).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(df):    \n",
    "    df['sent_count'] = df['final_message_string'].apply(lambda x: len(re.split(r'[.!?]+', x)) if x != '' and x != 'nan' else 0)\n",
    "    #num words\n",
    "    df['word_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'\\w+', x)) if x != '' and x != 'nan' else 0)\n",
    "    #avg sentence length (words per sentence)\n",
    "    df['avg_sent_length'] = df.apply(lambda row: row['word_count'] / row['sent_count'] if row['sent_count'] > 0 else 0, axis=1)\n",
    "    #avg word length (characters per word)\n",
    "    df['avg_word_length'] = df.apply(lambda row: len(row['final_message_string'].replace(' ', '')) / row['word_count'] if row['word_count'] > 0 else 0, axis=1)\n",
    "    #num exclamations (multiple ! coutn as one exclamation)\n",
    "    df['exclamation_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'!+', x)) if x else 0)\n",
    "    #num questions (multiple ? count as one question)\n",
    "    df['question_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'\\?+', x)) if x else 0)\n",
    "    #num emojis \n",
    "    df['emoji_count'] = df['final_message'].apply(lambda x: count_emojis(x) if x else 0)\n",
    "\n",
    "    print('Simple count based features extracted.')\n",
    "\n",
    "    ########## COUNT OF SELECTED POS TAGS ##########\n",
    "\n",
    "    #count nouns, verbs and adj\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    adjectives = []\n",
    "\n",
    "    for message in tqdm(df['final_message_string'], desc = 'Extracting POS Tag counts'):\n",
    "        noun, verb, adj = count_pos_tags(message)\n",
    "        nouns.append(noun)\n",
    "        verbs.append(verb)\n",
    "        adjectives.append(adj)\n",
    "                        \n",
    "    df['noun_count'] = nouns\n",
    "    df['verb_count'] = verbs\n",
    "    df['adj_count'] = adjectives\n",
    "\n",
    "    ########## FLESCH READING EASE SCORE ##########\n",
    "\n",
    "    textstat.set_lang('de')\n",
    "    #compute Flesch Reading Ease score on non-empty df\n",
    "    df['flesch_reading_ease'] = df['final_message_string'].apply(lambda x: textstat.flesch_reading_ease(x) if x.strip() != '' and x != 'nan' else np.nan)\n",
    "\n",
    "    #classify scores based on: https://pypi.org/project/textstat/\n",
    "    flesch_classes = []\n",
    "    for score in df['flesch_reading_ease']:\n",
    "        if score >= 0 and score < 30:\n",
    "            flesch_classes.append('very confusing')\n",
    "        elif score >= 30 and score < 50:\n",
    "            flesch_classes.append('difficult')\n",
    "        elif score >= 50 and score < 60:\n",
    "            flesch_classes.append('fairly difficult')\n",
    "        elif score >=60 and score < 70:\n",
    "            flesch_classes.append('standard')\n",
    "        elif score >=70 and score < 80:\n",
    "            flesch_classes.append('fairly easy')\n",
    "        elif score >=80 and score < 90:\n",
    "            flesch_classes.append('easy')\n",
    "        elif score >=90 and score < 101:\n",
    "            flesch_classes.append('very easy')\n",
    "        else:\n",
    "            flesch_classes.append('unclassified')\n",
    "        \n",
    "    df['flesch_reading_ease_class'] = flesch_classes\n",
    "\n",
    "    print('Flesch Reading Ease score extracted.')\n",
    "\n",
    "    ########## SENTIMENT ANALYSIS ##########\n",
    "\n",
    "    #load tokenizer and sentiment model\n",
    "    print('Loading sentiment model...')\n",
    "    sentiment_model = pipeline(model='aari1995/German_Sentiment')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('aari1995/German_Sentiment')  \n",
    "\n",
    "    pos_sent = []\n",
    "    neg_sent = []\n",
    "    neutral_sent = []\n",
    "\n",
    "    for message in tqdm(df['final_message_string'], desc = 'Extracting Sentiment'):\n",
    "        #if message is empty, don't calculate sentiment\n",
    "        if message == '' or message == 'nan':\n",
    "            pos_sent.append(np.nan)\n",
    "            neg_sent.append(np.nan)\n",
    "            neutral_sent.append(np.nan)\n",
    "        else:\n",
    "            #truncate message to max length model can handle\n",
    "            result = sentiment_model(message[:512])\n",
    "            sent = (result[0]['label'])\n",
    "            if sent == 'positive':\n",
    "                pos_sent.append(1)\n",
    "                neg_sent.append(0)\n",
    "                neutral_sent.append(0)\n",
    "            elif sent == 'negative':\n",
    "                pos_sent.append(0)\n",
    "                neg_sent.append(1)\n",
    "                neutral_sent.append(0)\n",
    "            elif sent == 'neutral':\n",
    "                pos_sent.append(0)\n",
    "                neg_sent.append(0)\n",
    "                neutral_sent.append(1)\n",
    "            else:\n",
    "                pos_sent.append(np.nan)\n",
    "                neg_sent.append(np.nan)\n",
    "                neutral_sent.append(np.nan)\n",
    "\n",
    "    df['positive_sentiment'] = pos_sent\n",
    "    df['negative_sentiment'] = neg_sent\n",
    "    df['neutral_sentiment'] = neutral_sent\n",
    "    print('Sentiment extracted.')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_cluster_metrics(n_cores, network_dict_list):\n",
    "    rep_list = []\n",
    "\n",
    "    pool = Pool(n_cores)\n",
    "\n",
    "    for result in tqdm(\n",
    "        pool.imap_unordered(func=calculate_cluster_results, iterable=network_dict_list),\n",
    "        total=len(network_dict_list)\n",
    "        ):\n",
    "            rep_list.append(result)\n",
    "\n",
    "    pool.close()\n",
    "    return rep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataframe into n_cores parts and return list of dicts\n",
    "def split_df(n_cores, df):\n",
    "    df_list = np.array_split(df, n_cores)\n",
    "    return [df_part.to_dict('records') for df_part in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores=4\n",
    "df_list = split_df(4, new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pool_cluster_metrics(n_cores, df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Aggregation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/aggregated/author_date_{sample_size}.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['message_count'] > 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of count columns to convert to percentages\n",
    "count_columns = [\n",
    "    'own_message',\n",
    "    'forwarded_message',\n",
    "    'positive_sentiment',\n",
    "    'negative_sentiment',\n",
    "    'neutral_sentiment',\n",
    "    'group_or_channel_channel',\n",
    "    'group_or_channel_group',\n",
    "    'flesch_reading_ease_class_difficult',\n",
    "    'flesch_reading_ease_class_easy',\n",
    "    'flesch_reading_ease_class_fairly difficult',\n",
    "    'flesch_reading_ease_class_fairly easy',\n",
    "    'flesch_reading_ease_class_standard',\n",
    "    'flesch_reading_ease_class_unclassified',\n",
    "    'flesch_reading_ease_class_very confusing',\n",
    "    'flesch_reading_ease_class_very easy'\n",
    "]\n",
    "\n",
    "# Convert counts to percentages row by row\n",
    "for index, row in df.iterrows():\n",
    "    for col in count_columns:\n",
    "        df.at[index, col] = row[col] / row['message_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../results/post-aggregation/author_date_200.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['message_count'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization - Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/samples/messages_sample_200.csv.gzip', compression='gzip')\n",
    "df_non = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(df):    \n",
    "    ########## FEATURE EXTRACTION ##########\n",
    "\n",
    "    #num sentences\n",
    "    df['sent_count'] = df['final_message_string'].apply(lambda x: len(re.split(r'[.!?]+', x)) if x != '' and x != 'nan' else 0)\n",
    "    #num words\n",
    "    df['word_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'\\w+', x)) if x != '' and x != 'nan' else 0)\n",
    "    #avg sentence length (words per sentence)\n",
    "    df['avg_sent_length'] = df.apply(lambda row: row['word_count'] / row['sent_count'] if row['sent_count'] > 0 else 0, axis=1)\n",
    "    #avg word length (characters per word)\n",
    "    df['avg_word_length'] = df.apply(lambda row: len(row['final_message_string'].replace(' ', '')) / row['word_count'] if row['word_count'] > 0 else 0, axis=1)\n",
    "    #num exclamations (multiple ! coutn as one exclamation)\n",
    "    df['exclamation_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'!+', x)) if x else 0)\n",
    "    #num questions (multiple ? count as one question)\n",
    "    df['question_count'] = df['final_message_string'].apply(lambda x: len(re.findall(r'\\?+', x)) if x else 0)\n",
    "    #num emojis \n",
    "    df['emoji_count'] = df['final_message'].apply(lambda x: count_emojis(x) if x else 0)\n",
    "\n",
    "    print('Simple count based features extracted.')\n",
    "\n",
    "    ########## COUNT OF SELECTED POS TAGS ##########\n",
    "\n",
    "    #count nouns, verbs and adj\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    adjectives = []\n",
    "\n",
    "    for message in tqdm(df['final_message_string'], desc = 'Extracting POS Tag counts'):\n",
    "        noun, verb, adj = count_pos_tags(message)\n",
    "        nouns.append(noun)\n",
    "        verbs.append(verb)\n",
    "        adjectives.append(adj)\n",
    "                        \n",
    "    df['noun_count'] = nouns\n",
    "    df['verb_count'] = verbs\n",
    "    df['adj_count'] = adjectives\n",
    "\n",
    "    ########## FLESCH READING EASE SCORE ##########\n",
    "\n",
    "    textstat.set_lang('de')\n",
    "    #compute Flesch Reading Ease score on non-empty df\n",
    "    df['flesch_reading_ease'] = df['final_message_string'].apply(lambda x: textstat.flesch_reading_ease(x) if x.strip() != '' and x != 'nan' else np.nan)\n",
    "\n",
    "    #classify scores based on: https://pypi.org/project/textstat/\n",
    "    flesch_classes = []\n",
    "    for score in df['flesch_reading_ease']:\n",
    "        if score >= 0 and score < 30:\n",
    "            flesch_classes.append('very confusing')\n",
    "        elif score >= 30 and score < 50:\n",
    "            flesch_classes.append('difficult')\n",
    "        elif score >= 50 and score < 60:\n",
    "            flesch_classes.append('fairly difficult')\n",
    "        elif score >=60 and score < 70:\n",
    "            flesch_classes.append('standard')\n",
    "        elif score >=70 and score < 80:\n",
    "            flesch_classes.append('fairly easy')\n",
    "        elif score >=80 and score < 90:\n",
    "            flesch_classes.append('easy')\n",
    "        elif score >=90 and score < 101:\n",
    "            flesch_classes.append('very easy')\n",
    "        else:\n",
    "            flesch_classes.append('unclassified')\n",
    "        \n",
    "    df['flesch_reading_ease_class'] = flesch_classes\n",
    "\n",
    "    print('Flesch Reading Ease score extracted.')\n",
    "\n",
    "    ########## SENTIMENT ANALYSIS ##########\n",
    "\n",
    "    #load tokenizer and sentiment model\n",
    "    print('Loading sentiment model...')\n",
    "    sentiment_model = pipeline(model='aari1995/German_Sentiment')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('aari1995/German_Sentiment')  \n",
    "\n",
    "    pos_sent = []\n",
    "    neg_sent = []\n",
    "    neutral_sent = []\n",
    "\n",
    "    for message in tqdm(df['final_message_string'], desc = 'Extracting Sentiment'):\n",
    "        #if message is empty, don't calculate sentiment\n",
    "        if message == '' or message == 'nan':\n",
    "            pos_sent.append(np.nan)\n",
    "            neg_sent.append(np.nan)\n",
    "            neutral_sent.append(np.nan)\n",
    "        else:\n",
    "            #truncate message to max length model can handle\n",
    "            result = sentiment_model(message[:512])\n",
    "            sent = (result[0]['label'])\n",
    "            if sent == 'positive':\n",
    "                pos_sent.append(1)\n",
    "                neg_sent.append(0)\n",
    "                neutral_sent.append(0)\n",
    "            elif sent == 'negative':\n",
    "                pos_sent.append(0)\n",
    "                neg_sent.append(1)\n",
    "                neutral_sent.append(0)\n",
    "            elif sent == 'neutral':\n",
    "                pos_sent.append(0)\n",
    "                neg_sent.append(0)\n",
    "                neutral_sent.append(1)\n",
    "            else:\n",
    "                pos_sent.append(np.nan)\n",
    "                neg_sent.append(np.nan)\n",
    "                neutral_sent.append(np.nan)\n",
    "\n",
    "    df['positive_sentiment'] = pos_sent\n",
    "    df['negative_sentiment'] = neg_sent\n",
    "    df['neutral_sentiment'] = neutral_sent\n",
    "    print('Sentiment extracted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, num_partitions):\n",
    "    # Split the dataframe into smaller chunks\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    # Create a pool of workers\n",
    "    with mp.Pool(num_partitions) as pool:\n",
    "        # Apply the function to each chunk\n",
    "        for df in pool.map(func, df_split):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = np.array_split(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start_non_parallel = time.time()\n",
    "########## FEATURE EXTRACTION ##########\n",
    "\n",
    "#num sentences\n",
    "df_non['sent_count'] = df_non['final_message_string'].apply(lambda x: len(re.split(r'[.!?]+', x)) if x != '' and x != 'nan' else 0)\n",
    "#num words\n",
    "df_non['word_count'] = df_non['final_message_string'].apply(lambda x: len(re.findall(r'\\w+', x)) if x != '' and x != 'nan' else 0)\n",
    "#avg sentence length (words per sentence)\n",
    "df_non['avg_sent_length'] = df_non.apply(lambda row: row['word_count'] / row['sent_count'] if row['sent_count'] > 0 else 0, axis=1)\n",
    "#avg word length (characters per word)\n",
    "df_non['avg_word_length'] = df_non.apply(lambda row: len(row['final_message_string'].replace(' ', '')) / row['word_count'] if row['word_count'] > 0 else 0, axis=1)\n",
    "#num exclamations (multiple ! coutn as one exclamation)\n",
    "df_non['exclamation_count'] = df_non['final_message_string'].apply(lambda x: len(re.findall(r'!+', x)) if x else 0)\n",
    "#num questions (multiple ? count as one question)\n",
    "df_non['question_count'] = df_non['final_message_string'].apply(lambda x: len(re.findall(r'\\?+', x)) if x else 0)\n",
    "#num emojis \n",
    "df_non['emoji_count'] = df_non['final_message'].apply(lambda x: count_emojis(x) if x else 0)\n",
    "\n",
    "print('Simple count based features extracted.')\n",
    "\n",
    "########## COUNT OF SELECTED POS TAGS ##########\n",
    "\n",
    "#count nouns, verbs and adj\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "\n",
    "for message in tqdm(df_non['final_message_string'], desc = 'Extracting POS Tag counts'):\n",
    "    noun, verb, adj = count_pos_tags(message)\n",
    "    nouns.append(noun)\n",
    "    verbs.append(verb)\n",
    "    adjectives.append(adj)\n",
    "                    \n",
    "df_non['noun_count'] = nouns\n",
    "df_non['verb_count'] = verbs\n",
    "df_non['adj_count'] = adjectives\n",
    "\n",
    "########## FLESCH READING EASE SCORE ##########\n",
    "\n",
    "textstat.set_lang('de')\n",
    "#compute Flesch Reading Ease score on non-empty df_non\n",
    "df_non['flesch_reading_ease'] = df_non['final_message_string'].apply(lambda x: textstat.flesch_reading_ease(x) if x.strip() != '' and x != 'nan' else np.nan)\n",
    "\n",
    "#classify scores based on: https://pypi.org/project/textstat/\n",
    "flesch_classes = []\n",
    "for score in df_non['flesch_reading_ease']:\n",
    "    if score >= 0 and score < 30:\n",
    "        flesch_classes.append('very confusing')\n",
    "    elif score >= 30 and score < 50:\n",
    "        flesch_classes.append('difficult')\n",
    "    elif score >= 50 and score < 60:\n",
    "        flesch_classes.append('fairly difficult')\n",
    "    elif score >=60 and score < 70:\n",
    "        flesch_classes.append('standard')\n",
    "    elif score >=70 and score < 80:\n",
    "        flesch_classes.append('fairly easy')\n",
    "    elif score >=80 and score < 90:\n",
    "        flesch_classes.append('easy')\n",
    "    elif score >=90 and score < 101:\n",
    "        flesch_classes.append('very easy')\n",
    "    else:\n",
    "        flesch_classes.append('unclassified')\n",
    "    \n",
    "df_non['flesch_reading_ease_class'] = flesch_classes\n",
    "\n",
    "print('Flesch Reading Ease score extracted.')\n",
    "\n",
    "########## SENTIMENT ANALYSIS ##########\n",
    "\n",
    "#load tokenizer and sentiment model\n",
    "print('Loading sentiment model...')\n",
    "sentiment_model = pipeline(model='aari1995/German_Sentiment')\n",
    "tokenizer = AutoTokenizer.from_pretrained('aari1995/German_Sentiment')  \n",
    "\n",
    "pos_sent = []\n",
    "neg_sent = []\n",
    "neutral_sent = []\n",
    "\n",
    "for message in tqdm(df_non['final_message_string'], desc = 'Extracting Sentiment'):\n",
    "    #if message is empty, don't calculate sentiment\n",
    "    if message == '' or message == 'nan':\n",
    "        pos_sent.append(np.nan)\n",
    "        neg_sent.append(np.nan)\n",
    "        neutral_sent.append(np.nan)\n",
    "    else:\n",
    "        #truncate message to max length model can handle\n",
    "        result = sentiment_model(message[:512])\n",
    "        sent = (result[0]['label'])\n",
    "        if sent == 'positive':\n",
    "            pos_sent.append(1)\n",
    "            neg_sent.append(0)\n",
    "            neutral_sent.append(0)\n",
    "        elif sent == 'negative':\n",
    "            pos_sent.append(0)\n",
    "            neg_sent.append(1)\n",
    "            neutral_sent.append(0)\n",
    "        elif sent == 'neutral':\n",
    "            pos_sent.append(0)\n",
    "            neg_sent.append(0)\n",
    "            neutral_sent.append(1)\n",
    "        else:\n",
    "            pos_sent.append(np.nan)\n",
    "            neg_sent.append(np.nan)\n",
    "            neutral_sent.append(np.nan)\n",
    "\n",
    "df_non['positive_sentiment'] = pos_sent\n",
    "df_non['negative_sentiment'] = neg_sent\n",
    "df_non['neutral_sentiment'] = neutral_sent\n",
    "print('Sentiment extracted.')\n",
    "\n",
    "time_end_non_parallel = time.time()\n",
    "print(f'Non-parallel execution time: {time_end_non_parallel - time_start_non_parallel} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv(f'../data/samples/messages_sample_200.csv.gzip', compression='gzip').drop(columns=['Unnamed: 0'], axis=1)\n",
    "messages['final_message_string'] = messages['final_message_string'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and sentiment model\n",
    "print('Loading sentiment model...')\n",
    "sentiment_model = pipeline(model='aari1995/German_Sentiment')\n",
    "tokenizer = AutoTokenizer.from_pretrained('aari1995/German_Sentiment')\n",
    "\n",
    "# Define a function to process a single message\n",
    "def analyze_sentiment(message):\n",
    "    if message == '' or message == 'nan':\n",
    "        return np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        # Truncate message to max length model can handle\n",
    "        result = sentiment_model(message[:512])\n",
    "        sent = result[0]['label']\n",
    "        if sent == 'positive':\n",
    "            return 1, 0, 0\n",
    "        elif sent == 'negative':\n",
    "            return 0, 1, 0\n",
    "        elif sent == 'neutral':\n",
    "            return 0, 0, 1\n",
    "        else:\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "# Initialize lists to store sentiment results\n",
    "pos_sent = []\n",
    "neg_sent = []\n",
    "neutral_sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ThreadPoolExecutor to parallelize sentiment analysis\n",
    "print('Starting sentiment extraction...')\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit tasks and store futures\n",
    "    futures = [executor.submit(analyze_sentiment, msg) for msg in messages['final_message_string']]\n",
    "    # Process results as they become available\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc='Extracting Sentiment'):\n",
    "        pos, neg, neutral = future.result()\n",
    "        pos_sent.append(pos)\n",
    "        neg_sent.append(neg)\n",
    "        neutral_sent.append(neutral)\n",
    "\n",
    "# Add sentiment results to the DataFrame\n",
    "messages['positive_sentiment'] = pos_sent\n",
    "messages['negative_sentiment'] = neg_sent\n",
    "messages['neutral_sentiment'] = neutral_sent\n",
    "print('Sentiment extraction done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# was_forwarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200\n",
    "pre_agg = pd.read_csv(f'../results/pre-aggregation/liwcANDfeatures_results_{sample_size}.csv.gzip', compression='gzip')\n",
    "print('Dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_agg = pd.get_dummies(pre_agg, columns=['group_or_channel'])\n",
    "print('Dummies for categorial variables created.')\n",
    "messages = pre_agg[['author', 'own_message', 'forwarded_message', 'fwd_author', 'UID_key', 'group_name', 'date']]\n",
    "pre_agg = pre_agg[pre_agg['own_message'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    # SUM\n",
    "    'noun_count': 'sum',\n",
    "    'verb_count': 'sum',\n",
    "    'adj_count': 'sum',\n",
    "    'positive_sentiment': 'sum',\n",
    "    'negative_sentiment': 'sum',\n",
    "    'neutral_sentiment': 'sum',\n",
    "    'group_or_channel_channel': 'sum',\n",
    "    'group_or_channel_group': 'sum',\n",
    "\n",
    "    # AVG\n",
    "    'sent_count': 'mean',\n",
    "    'word_count': 'mean',\n",
    "    'avg_sent_length': 'mean',\n",
    "    'avg_word_length': 'mean',\n",
    "    'exclamation_count': 'mean',\n",
    "    'question_count': 'mean',\n",
    "    'emoji_count': 'mean',\n",
    "    'flesch_reading_ease': 'mean',\n",
    "    'liwc_I': 'mean',\n",
    "    'liwc_We': 'mean',\n",
    "    'liwc_You': 'mean',\n",
    "    'liwc_Other': 'mean',\n",
    "    'liwc_Affect': 'mean',\n",
    "    \n",
    "    # ' '.JOIN\n",
    "    'final_message': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    'final_message_string': lambda x: ' '.join(x.dropna().astype(str)),\n",
    "}\n",
    "\n",
    "# Aggregation dictionary for message ratios\n",
    "agg_dict_messages = {\n",
    "    'own_message': 'sum',\n",
    "    'forwarded_message': 'sum',\n",
    "    'UID_key': 'count'\n",
    "}\n",
    "\n",
    "########## RENAMING COLUMNS ##########\n",
    "\n",
    "rename_dict = {'group_or_channel_channel': 'channel_messages', 'group_or_channel_group': 'group_messages', 'UID_key': 'total_message_count'}\n",
    "\n",
    "\n",
    "print('Aggregating per author and group...')\n",
    "#aggregate linguistic features\n",
    "agg_author_group = pre_agg.groupby(['author', 'group_name']).agg(agg_dict)\n",
    "agg_author_group = agg_author_group.rename(columns=rename_dict)\n",
    "#aggregate message ratios\n",
    "agg_author_group_messages = messages.groupby(['author', 'group_name']).agg(agg_dict_messages)\n",
    "agg_author_group_messages = agg_author_group_messages.rename(columns=rename_dict)\n",
    "#concat based on author and group columns\n",
    "agg_author_group = pd.merge(\n",
    "    left = agg_author_group,\n",
    "    right = agg_author_group_messages,\n",
    "    how = 'outer',\n",
    "    left_on = ['author', 'group_name'],\n",
    "    right_on = ['author', 'group_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_author_group.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_author_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/samples/messages_sample_{sample_size}.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of authors in each group\n",
    "grouped_authors = df.groupby('group_name')['author'].apply(list)\n",
    "\n",
    "# get combinations of two authors in each group\n",
    "edges = []\n",
    "for authors in grouped_authors:\n",
    "    if len(authors) > 1:\n",
    "        edges += combinations(sorted(set(authors)), 2)\n",
    "\n",
    "# count occurences of combo to determine edge weight\n",
    "edge_weights = Counter(edges)\n",
    "\n",
    "# save as df\n",
    "edgelist = pd.DataFrame(edge_weights.items(), columns=['edge', 'weight'])\n",
    "edgelist[['author_1', 'author_2']] = pd.DataFrame(edgelist['edge'].tolist(), index=edgelist.index)\n",
    "edgelist = edgelist.drop(columns='edge')\n",
    "edgelist.to_csv(f'../data/edgelists/author_{sample_size}_edgelist.csv', index=False)\n",
    "\n",
    "# Final weighted edgelist with columns 'author_1', 'author_2', and 'weight'\n",
    "print(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINNALY FIXED Toxicity Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_detection(message, client):\n",
    "    analyze_request = {\n",
    "        'comment': { 'text': f\"{message}\" },\n",
    "        'languages' : [\"de\"],\n",
    "        'requestedAttributes': {'TOXICITY': {}},\n",
    "    }\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    toxic =response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "    return toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#initialize column\n",
    "toxicity = []\n",
    "\n",
    "for i in tqdm(range(len(results))):\n",
    "    row = results.iloc[i]\n",
    "    message = row['final_message_string']\n",
    "    if row['own_message'] == 1:\n",
    "        tox = toxicity_detection(message, client)\n",
    "        toxicity.append(tox)\n",
    "    else:\n",
    "        toxicity.append(np.nan)\n",
    "\n",
    "results['toxicity'] = toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Cluster Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../results/post-aggregation/author_full.csv.gzip', compression='gzip')\n",
    "# load \"raw\" dataset to analyse adjacency matrix\n",
    "data = pd.read_csv('../data/samples/messages_sample_full.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = DAEGC(30, 128, 9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = DAEGC(30, 128, 9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = DAEGC(30, 128, 9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_state_dict(torch.load('../model/DAEGC_3Clusters.pkl'))\n",
    "model_3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.load_state_dict(torch.load('../model/DAEGC_4Clusters.pkl'))\n",
    "model_4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model_5.load_state_dict(torch.load('../model/DAEGC_5Clusters.pkl'))\n",
    "model_5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, adj_norm = create_adj_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = create_feature_matrix(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = get_M(adj_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get soft embeddings & cluster assignments\n",
    "with torch.no_grad():\n",
    "    _, z_3, q_3 = model_3(x, adj_norm, M)\n",
    "    _, z_4, q_4 = model_4(x, adj_norm, M)\n",
    "    _, z_5, q_5 = model_5(x, adj_norm, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster assignments\n",
    "q3_labels = torch.argmax(q_3, dim=1)\n",
    "# count number of nodes in each cluster\n",
    "q3_cluster_count = Counter(q3_labels.numpy())\n",
    "print('Cluster Assignment for 3 Clusters:', q3_cluster_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster assignments\n",
    "q4_labels = torch.argmax(q_4, dim=1)\n",
    "# count number of nodes in each cluster\n",
    "q4_cluster_count = Counter(q4_labels.numpy())\n",
    "print('Cluster Assignment for 4 Clusters:', q4_cluster_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster assignments\n",
    "q5_labels = torch.argmax(q_5, dim=1)\n",
    "# count number of nodes in each cluster\n",
    "q5_cluster_count = Counter(q5_labels.numpy())\n",
    "print('Cluster Assignment for 5 Clusters:', q5_cluster_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cluster assignments to features\n",
    "features['cluster_3'] = q3_labels.numpy()\n",
    "features['cluster_4'] = q4_labels.numpy()\n",
    "features['cluster_5'] = q5_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('../results/author_full_clusters.csv.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save node embeddings\n",
    "np.save('../results/author_full_z_3.npy', z_3.numpy())\n",
    "np.save('../results/author_full_z_4.npy', z_4.numpy())\n",
    "np.save('../results/author_full_z_5.npy', z_5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../results/author_full_features_and_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../results/post-aggregation/author_full.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique ids of len(df) to anonymize authors\n",
    "ids = list(range(len(test)))\n",
    "random.shuffle(ids)\n",
    "\n",
    "# create dict to map authors to ids\n",
    "author_to_id = dict(zip(test['author'], ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'../data/samples/messages_sample_full.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymize auhtor according to dict in both agg_data and data\n",
    "agg_data['author_id'] = agg_data['author'].map(author_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['author_id'] = data['author'].map(author_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename author_id to author and drop old auhtor column\n",
    "agg_data = agg_data.drop(columns='author', axis=1)\n",
    "agg_data = agg_data.rename(columns={'author_id': 'author'})\n",
    "\n",
    "data = data.drop(columns='author', axis=1)\n",
    "data = data.rename(columns={'author_id': 'author'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='author', axis=1)\n",
    "data = data.rename(columns={'author_id': 'author'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.to_csv('../results/post-aggregation/author_full.csv.gzip', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/samples/messages_sample_full.csv.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict\n",
    "import json\n",
    "\n",
    "with open('../data/author_to_id.json', 'w') as f:\n",
    "    json.dump(author_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/samples/messages_sample_full.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agg_data = pd.read_csv('../results/post-aggregation/author_full.csv.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author ids that are in agg_data but not in data\n",
    "missing_authors = set(test_agg_data['author']) - set(test_data['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_authors = test_data.groupby('group_name')['author'].apply(set)\n",
    "\n",
    "# get unique authors and map them to indices\n",
    "authors = sorted(set(str(author) for author in test_data['author']))\n",
    "author_idx_map = {author: idx for idx, author in enumerate(authors)}\n",
    "\n",
    "# Check for missing authors\n",
    "missing_authors = [author for author in authors if author not in author_idx_map]\n",
    "if missing_authors:\n",
    "    print(f\"Missing authors in author_idx_map: {missing_authors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get combinations of two authors in each group\n",
    "edges = []\n",
    "for authors_in_group in grouped_authors:\n",
    "    if len(authors_in_group) > 1:\n",
    "        edges += combinations(authors_in_group, 2)\n",
    "\n",
    "# count occurrences of each combination to determine edge weight\n",
    "edge_weights = Counter(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists for COO sparse matrix format (row, col, data)\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (author_1, author_2), weight in edge_weights.items():\n",
    "    idx_1 = author_idx_map[author_1]\n",
    "    idx_2 = author_idx_map[author_2]\n",
    "\n",
    "    # Add both directions since the matrix is symmetric\n",
    "    row_indices.append(idx_1)\n",
    "    col_indices.append(idx_2)\n",
    "    data.append(weight)\n",
    "    \n",
    "    row_indices.append(idx_2)\n",
    "    col_indices.append(idx_1)\n",
    "    data.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = author_idx_map['16384']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_feature_matrix(agg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_agg_data.fillna(0)\n",
    "# Create empty lists for COO sparse matrix format (row, col, data)\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "data = []\n",
    "feature_columns = dataset.columns\n",
    "feature_columns = [feat for feat in feature_columns if (feat != 'final_message_string') & (feat != 'final_message') & (feat != 'author') & (feat != 'avg_flesch_reading_ease_class')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load agg_data\n",
    "agg_data = pd.read_csv('../results/author_full_features_and_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/author_full_edge_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# edge_list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m edgelist \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../results/author_full_edge_list.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/author_full_edge_list.csv'"
     ]
    }
   ],
   "source": [
    "# edge_list\n",
    "edgelist = pd.read_csv('../results/author_full_edge_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('../results/author_full_adj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# calculate centrality measures and add to agg_data\n",
    "\n",
    "# create graph\n",
    "#G = nx.from_pandas_edgelist(edgelist, 'Source', 'Target')\n",
    "G = nx.from_numpy_array(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data['degree_centrality'] = agg_data['author'].map(degree_centrality)\n",
    "agg_data.to_csv('../results/centrality.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "katz = nx.katz_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data['katz'] = agg_data['author'].map(katz)\n",
    "agg_data.to_csv('../results/centrality.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = pd.read_csv('../results/author_full_features_and_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['noun_count', 'verb_count', 'adj_count', 'positive_sentiment',\n",
       "       'negative_sentiment', 'neutral_sentiment', 'channel_messages',\n",
       "       'group_messages', 'sent_count', 'word_count', 'avg_sent_length',\n",
       "       'avg_word_length', 'exclamation_count', 'question_count', 'emoji_count',\n",
       "       'flesch_reading_ease', 'liwc_I', 'liwc_We', 'liwc_You', 'liwc_Other',\n",
       "       'liwc_Affect', 'own_message', 'forwarded_message',\n",
       "       'total_message_count', 'was_forwarded', 'own_message_count',\n",
       "       'forwarded_message_count', 'action_quotient', 'sentiment_quotient',\n",
       "       'avg_flesch_reading_ease_class', 'toxicity', 'author', 'cluster',\n",
       "       'cluster_0_prob', 'cluster_1_prob', 'cluster_2_prob', 'cluster_3_prob',\n",
       "       'cluster_4_prob', 'cluster_5_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = agg_data.iloc[:,:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix created.\n",
      "Feature tensor shape: torch.Size([16885, 30])\n"
     ]
    }
   ],
   "source": [
    "features_tensor = create_feature_matrix(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('../results/author_full_adj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format adj as tensor\n",
    "adj_tensor = torch.FloatTensor(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized adjacency matrix with self-loop is used in the model\n",
    "adj_norm = adj_tensor + torch.eye(adj_tensor.shape[0])\n",
    "adj_norm = normalize(adj_norm.numpy(), norm='l1')\n",
    "adj_norm = torch.from_numpy(adj_norm).to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix shape: (16885, 16885)\n"
     ]
    }
   ],
   "source": [
    "M = get_M(adj_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAEGC(30, 128, 9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../model/DAEGC.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the soft cluster assignment probabilities (q) for a specific cluster\n",
    "def get_cluster_probability(model, x, adj_norm, M, cluster_index):\n",
    "    _, _, q = model(x, adj_norm, M)  # Get cluster assignments (soft probabilities)\n",
    "    return q[:, cluster_index].detach().numpy()  # Extract the probability for the specified cluster\n",
    "\n",
    "# Set up SHAP Explainer for each cluster\n",
    "def get_shap_values(model, x, adj_norm, M, cluster_index):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x_numpy = x.detach().numpy()  # Detach and convert tensor to NumPy\n",
    "    else:\n",
    "        x_numpy = x \n",
    "\n",
    "    # Define a function wrapper for SHAP's KernelExplainer\n",
    "    def cluster_probability_fn(data):\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32)  # Convert data back to tensor\n",
    "        if torch.cuda.is_available():  # Move to GPU if applicable\n",
    "            data_tensor = data_tensor.cuda()\n",
    "        return get_cluster_probability(model, data_tensor, adj_norm, M, cluster_index)\n",
    "\n",
    "    # Initialize SHAP KernelExplainer\n",
    "    explainer = shap.KernelExplainer(cluster_probability_fn, x_numpy)\n",
    "    \n",
    "    # Compute SHAP values for the specified cluster\n",
    "    shap_values = explainer.shap_values(x_numpy)  # x is your input data\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16885 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|          | 0/16885 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16885x16885 and 1x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values_cluster_0 \u001b[38;5;241m=\u001b[39m \u001b[43mget_shap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m, in \u001b[0;36mget_shap_values\u001b[0;34m(model, x, adj_norm, M, cluster_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(cluster_probability_fn, x_numpy)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Compute SHAP values for the specified cluster\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_numpy\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# x is your input data\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shap_values\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:271\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[1;32m    270\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[0;32m--> 271\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    273\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:322\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mf(instance\u001b[38;5;241m.\u001b[39mconvert_to_df())\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_out, (pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mSeries)):\n\u001b[1;32m    324\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m model_out\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mget_shap_values.<locals>.cluster_probability_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# Move to GPU if applicable\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     data_tensor \u001b[38;5;241m=\u001b[39m data_tensor\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_cluster_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mget_cluster_probability\u001b[0;34m(model, x, adj_norm, M, cluster_index)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cluster_probability\u001b[39m(model, x, adj_norm, M, cluster_index):\n\u001b[0;32m----> 3\u001b[0m     _, _, q \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get cluster assignments (soft probabilities)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q[:, cluster_index]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/src/DAEGC/DAEGC.py:56\u001b[0m, in \u001b[0;36mDAEGC.forward\u001b[0;34m(self, x, adj_norm, M)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj_norm, M):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# get predicted adj matrix and node embeddings z\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     A_pred, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# additional GAT layer\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layer1(z, adj_norm, M)\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/src/DAEGC/GAT.py:85\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, adj, M)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj, M):\n\u001b[0;32m---> 85\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(h, adj, M)\n\u001b[1;32m     87\u001b[0m     z \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(h, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/thesis_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/CSH-Internship/src/DAEGC/GAT.py:50\u001b[0m, in \u001b[0;36mGATLayer.forward\u001b[0;34m(self, input, adj, M, concat)\u001b[0m\n\u001b[1;32m     48\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(adj \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, attn_dense, zero_vec)\n\u001b[1;32m     49\u001b[0m attention \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(adj, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m h_prime \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39melu(h_prime)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16885x16885 and 1x128)"
     ]
    }
   ],
   "source": [
    "shap_values_cluster_0 = get_shap_values(model, features_tensor, adj_norm, M, cluster_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print SHAP values for cluster 0\n",
    "print(\"SHAP values for cluster 0:\", shap_values_cluster_0)\n",
    "np.save('shap_values_cluster_0.npy', shap_values_cluster_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
